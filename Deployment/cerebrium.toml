[cerebrium.deployment]
name = "onnx-inference-mtailor"
disable_auth = false
include = ["./*", "resnet-model.onnx", "handler.py", "cerebrium.toml"]
exclude = ["*/.git", "*.pyc", "__pycache__", "Other"]

[cerebrium.hardware]
cpu = 2.0
memory = 12.0
compute = "CPU"

[cerebrium.runtime.custom]
port = 8192
healthcheck_endpoint = "/health"
dockerfile_path = "./Dockerfile"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 5
cooldown = 30
replica_concurrency = 1
response_grace_period = 900
scaling_metric = "concurrency_utilization"
scaling_target = 100
scaling_buffer = 0
roll_out_duration_seconds = 0
